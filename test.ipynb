{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229b14be",
   "metadata": {},
   "source": [
    "# Uditya Narayan Tiwari\n",
    "- Reg No: 23BAI10543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66887bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d8ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Uditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Uditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acce7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of Artificial Intelligence.\n",
    "It focuses on enabling machines to understand, analyze, and generate human language.\n",
    "NLP is widely used in applications such as chatbots, sentiment analysis,\n",
    "machine translation, and information retrieval systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b43018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Validation Passed (English Text)\n"
     ]
    }
   ],
   "source": [
    "def is_english(text):\n",
    "    return bool(re.match(r'^[A-Za-z0-9\\s().,!\\n-]+$', text))\n",
    "\n",
    "\n",
    "if not is_english(text):\n",
    "    print(\"Script Validation Failed\")\n",
    "else:\n",
    "    print(\"Script Validation Passed (English Text)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cdcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokens:\n",
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'Artificial', 'Intelligence', '.', 'It', 'focuses', 'on', 'enabling', 'machines', 'to', 'understand', ',', 'analyze', ',', 'and', 'generate', 'human', 'language', '.', 'NLP', 'is', 'widely', 'used', 'in', 'applications', 'such', 'as', 'chatbots', ',', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'and', 'information', 'retrieval', 'systems', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"\\nTokens:\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee2ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Stop Words Removal:\n",
      "['Natural', 'Language', 'Processing', 'NLP', 'subfield', 'Artificial', 'Intelligence', 'focuses', 'enabling', 'machines', 'understand', 'analyze', 'generate', 'human', 'language', 'NLP', 'widely', 'used', 'applications', 'chatbots', 'sentiment', 'analysis', 'machine', 'translation', 'information', 'retrieval', 'systems']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [\n",
    "word for word in tokens \n",
    "if word.lower() not in stop_words and word.isalpha()\n",
    "]\n",
    "print(\"\\nAfter Stop Words Removal:\")\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ac9c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Stemming:\n",
      "['natur', 'languag', 'process', 'nlp', 'subfield', 'artifici', 'intellig', 'focus', 'enabl', 'machin', 'understand', 'analyz', 'gener', 'human', 'languag', 'nlp', 'wide', 'use', 'applic', 'chatbot', 'sentiment', 'analysi', 'machin', 'translat', 'inform', 'retriev', 'system']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "print(\"\\nAfter Stemming:\")\n",
    "print(stemmed_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
